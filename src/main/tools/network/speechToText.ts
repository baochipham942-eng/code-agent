// ============================================================================
// Speech to Text Tool - è¯­éŸ³è½¬æ–‡å­—
// ä½¿ç”¨æ™ºè°± GLM-ASR-2512 æ¨¡å‹
// ============================================================================

import * as fs from 'fs';
import * as path from 'path';
import type { Tool, ToolContext, ToolExecutionResult } from '../toolRegistry';
import { getConfigService } from '../../services';
import { createLogger } from '../../services/infra/logger';

const logger = createLogger('SpeechToText');

// é…ç½®
const CONFIG = {
  API_URL: 'https://open.bigmodel.cn/api/paas/v4/audio/transcriptions',
  MODEL: 'glm-asr-2512',
  TIMEOUT_MS: 60000, // 60 ç§’è¶…æ—¶
  MAX_FILE_SIZE_MB: 25,
  MAX_DURATION_SECONDS: 30,
  SUPPORTED_FORMATS: ['.wav', '.mp3', '.m4a', '.flac', '.ogg', '.webm'],
};

/**
 * å¸¦è¶…æ—¶çš„ fetch
 */
async function fetchWithTimeout(
  url: string,
  options: RequestInit,
  timeoutMs: number
): Promise<Response> {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal,
    });
    return response;
  } finally {
    clearTimeout(timeoutId);
  }
}

interface SpeechToTextParams {
  file_path: string;
  hotwords?: string; // çƒ­è¯ï¼Œç”¨äºæé«˜è¯†åˆ«å‡†ç¡®ç‡
  prompt?: string; // ä¸Šä¸‹æ–‡æç¤º
}

interface ZhipuASRResponse {
  id?: string;
  text?: string;
  error?: {
    code: string;
    message: string;
  };
}

/**
 * è°ƒç”¨æ™ºè°± ASR API
 */
async function callZhipuASR(
  apiKey: string,
  audioData: Buffer,
  fileName: string,
  params: SpeechToTextParams
): Promise<string> {
  // ä½¿ç”¨ base64 æ–¹å¼å‘é€ï¼Œé¿å… Buffer/Blob ç±»å‹å…¼å®¹é—®é¢˜
  const base64Audio = audioData.toString('base64');
  const mimeType = getMimeType(fileName);

  // ç›´æ¥å‘é€ JSON è¯·æ±‚è€Œé FormData
  const jsonBody = {
    model: CONFIG.MODEL,
    file: `data:${mimeType};base64,${base64Audio}`,
    stream: false,
    ...(params.hotwords && { hotwords: params.hotwords }),
    ...(params.prompt && { prompt: params.prompt }),
  };

  logger.info('[è¯­éŸ³è½¬æ–‡å­—] è°ƒç”¨æ™ºè°± ASR API', {
    fileName: path.basename(fileName),
    fileSize: audioData.length,
    hasHotwords: !!params.hotwords,
    hasPrompt: !!params.prompt,
  });

  const response = await fetchWithTimeout(
    CONFIG.API_URL,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify(jsonBody),
    },
    CONFIG.TIMEOUT_MS
  );

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`æ™ºè°± ASR API é”™è¯¯: ${response.status} - ${errorText}`);
  }

  const result: ZhipuASRResponse = await response.json();

  if (result.error) {
    throw new Error(`ASR é”™è¯¯: ${result.error.message} (${result.error.code})`);
  }

  if (!result.text) {
    throw new Error('ASR æœªè¿”å›è¯†åˆ«ç»“æœ');
  }

  logger.info('[è¯­éŸ³è½¬æ–‡å­—] è¯†åˆ«æˆåŠŸ', {
    textLength: result.text.length,
  });

  return result.text;
}

/**
 * è·å–éŸ³é¢‘æ–‡ä»¶çš„ MIME ç±»å‹
 */
function getMimeType(filePath: string): string {
  const ext = path.extname(filePath).toLowerCase();
  const mimeTypes: Record<string, string> = {
    '.wav': 'audio/wav',
    '.mp3': 'audio/mpeg',
    '.m4a': 'audio/mp4',
    '.flac': 'audio/flac',
    '.ogg': 'audio/ogg',
    '.webm': 'audio/webm',
  };
  return mimeTypes[ext] || 'audio/wav';
}

/**
 * éªŒè¯æ–‡ä»¶
 */
function validateFile(filePath: string, stats: fs.Stats): void {
  // æ£€æŸ¥æ‰©å±•å
  const ext = path.extname(filePath).toLowerCase();
  if (!CONFIG.SUPPORTED_FORMATS.includes(ext)) {
    throw new Error(
      `ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: ${ext}ã€‚æ”¯æŒçš„æ ¼å¼: ${CONFIG.SUPPORTED_FORMATS.join(', ')}`
    );
  }

  // æ£€æŸ¥æ–‡ä»¶å¤§å°
  const sizeMB = stats.size / (1024 * 1024);
  if (sizeMB > CONFIG.MAX_FILE_SIZE_MB) {
    throw new Error(
      `æ–‡ä»¶è¿‡å¤§: ${sizeMB.toFixed(2)} MBã€‚æœ€å¤§æ”¯æŒ ${CONFIG.MAX_FILE_SIZE_MB} MB`
    );
  }
}

export const speechToTextTool: Tool = {
  name: 'speech_to_text',
  description: `è¯­éŸ³è½¬æ–‡å­—ã€‚

ä½¿ç”¨æ™ºè°± GLM-ASR-2512 æ¨¡å‹å°†éŸ³é¢‘è½¬ä¸ºæ–‡å­—ã€‚

å‚æ•°ï¼š
- file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
- hotwords: çƒ­è¯åˆ—è¡¨ï¼Œç”¨äºæé«˜ç‰¹å®šè¯æ±‡è¯†åˆ«ç‡ï¼ˆå¯é€‰ï¼‰
- prompt: ä¸Šä¸‹æ–‡æç¤ºï¼Œå¸®åŠ©æ¨¡å‹ç†è§£å†…å®¹ï¼ˆå¯é€‰ï¼‰

æ”¯æŒæ ¼å¼ï¼š${CONFIG.SUPPORTED_FORMATS.join(', ')}
é™åˆ¶ï¼šæœ€å¤§ ${CONFIG.MAX_FILE_SIZE_MB}MBï¼Œæœ€é•¿ ${CONFIG.MAX_DURATION_SECONDS} ç§’

ç¤ºä¾‹ï¼š
\`\`\`
speech_to_text { "file_path": "/path/to/audio.wav" }
speech_to_text { "file_path": "meeting.mp3", "hotwords": "æ™ºè°±,GLM,API" }
speech_to_text { "file_path": "lecture.wav", "prompt": "è¿™æ˜¯ä¸€æ®µå…³äºäººå·¥æ™ºèƒ½çš„è®²åº§" }
\`\`\`

æ³¨æ„ï¼šéœ€è¦é…ç½®æ™ºè°± API Key`,
  generations: ['gen5', 'gen6', 'gen7', 'gen8'],
  requiresPermission: true,
  permissionLevel: 'read',
  inputSchema: {
    type: 'object',
    properties: {
      file_path: {
        type: 'string',
        description: 'éŸ³é¢‘æ–‡ä»¶è·¯å¾„',
      },
      hotwords: {
        type: 'string',
        description: 'çƒ­è¯åˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œç”¨äºæé«˜ç‰¹å®šè¯æ±‡è¯†åˆ«ç‡',
      },
      prompt: {
        type: 'string',
        description: 'ä¸Šä¸‹æ–‡æç¤ºï¼Œå¸®åŠ©æ¨¡å‹ç†è§£å†…å®¹',
      },
    },
    required: ['file_path'],
  },

  async execute(
    params: Record<string, unknown>,
    context: ToolContext
  ): Promise<ToolExecutionResult> {
    const typedParams = params as unknown as SpeechToTextParams;
    const startTime = Date.now();

    try {
      const configService = getConfigService();
      const zhipuApiKey = configService.getApiKey('zhipu');

      if (!zhipuApiKey) {
        return {
          success: false,
          error: 'è¯­éŸ³è½¬æ–‡å­—éœ€è¦é…ç½®æ™ºè°± API Keyã€‚è¯·åœ¨è®¾ç½®ä¸­æ·»åŠ æ™ºè°± API Keyã€‚',
        };
      }

      // è§£ææ–‡ä»¶è·¯å¾„
      let filePath = typedParams.file_path;
      if (!path.isAbsolute(filePath)) {
        filePath = path.join(context.workingDirectory, filePath);
      }

      // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      if (!fs.existsSync(filePath)) {
        return {
          success: false,
          error: `æ–‡ä»¶ä¸å­˜åœ¨: ${filePath}`,
        };
      }

      // éªŒè¯æ–‡ä»¶
      const stats = fs.statSync(filePath);
      validateFile(filePath, stats);

      const fileSizeMB = (stats.size / (1024 * 1024)).toFixed(2);

      context.emit?.('tool_output', {
        tool: 'speech_to_text',
        message: `ğŸ¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³ (${fileSizeMB} MB)...`,
      });

      // è¯»å–æ–‡ä»¶
      const audioData = fs.readFileSync(filePath);

      // è°ƒç”¨ ASR API
      const text = await callZhipuASR(zhipuApiKey, audioData, filePath, typedParams);

      const processingTime = Date.now() - startTime;

      return {
        success: true,
        output: text,
        metadata: {
          filePath,
          fileSizeMB: parseFloat(fileSizeMB),
          textLength: text.length,
          processingTimeMs: processingTime,
          model: CONFIG.MODEL,
        },
      };
    } catch (error: any) {
      logger.error('[è¯­éŸ³è½¬æ–‡å­—] å¤±è´¥', { error: error.message });
      return {
        success: false,
        error: `è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: ${error.message}`,
      };
    }
  },
};
